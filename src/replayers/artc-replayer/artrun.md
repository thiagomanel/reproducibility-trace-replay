% artrun(1) ARTC
% Zev Weiss <zev@cs.wisc.edu>
% September 2013

# NAME

artrun - `artc`(1)'s companion replay engine

# SYNOPSIS

artrun [FLAGS] *BENCHMARK* *RUNDIR*

# DESCRIPTION

`artrun` loads *BENCHMARK*, a shared library compiled from code
generated by `artc`(1), and replays the trace it was compiled from
within *RUNDIR*.

`artrun` will create a subdirectory in *RUNDIR* called `bench_dir` and
perform replay within that; this is a preventative measure to avoid
accidental massive data loss if a benchmark is run in the wrong
directory by mistake (since `artrun`'s default initialization sequence
removes all files not listed in the init-listing used to compile
*BENCHMARK*).

# OPTIONS

-C, \--ignore-cpu

  : Ignore CPU utilization when computing predelay (only applicable on
    benchmarks compiled with `artc`(1)'s *-i*/*--iostat* flag).


-c *N*, \--predelay-multiplier=*N*

  : Multiply all predelay times by *N* (floating-point, 1.0 by
    default).  \`-c 0' thus yields AFAP (as-fast-as-possible) replay.


-d *THINGS*, \--debug=*THINGS*

  : Enable debugging of a comma-separated list of *THINGS*: *fds*
    (file descriptors), *paths*, *aio* (asynchronous I/O), and
    *threads*.


-E, \--eager-threadspawn

  : By default `artrun`'s replay threads spawn other threads at
    appropriate times where indicated by the artifical "threadspawn"
    events inserted by `artc`(1) in *BENCHMARK*; `artrun` only
    explicitly spawns the very first thread in the trace.  This flag
    overrides this behavior so that `artrun` instead spawns all
    threads in the benchmark immediately, relying on the enforcement
    of ordering constraints to sort out what happens when.  Note that
    this has the potential to spawn very large numbers of threads
    (depending on what's in *BENCHMARK*), possibly exceeding resource
    limits.


-F *P*, \--fsync-point=*P*

  : Sets the operation used to replay `fsync`(2) calls. *P* is a
    floating point number in the range [0,1] (or [0,2] on Mac OS X).
    At 0, all `fsync`s are replayed as no-ops (i.e. skipped); at 1 all
    `fsync`s are replayed as `fsync`, values in between determine the
    likelihood of one being chosen vs. the other in a pseudo-random
    fashion.  On Mac OS X, the additional range [1,2] selects between
    `fsync` and `fcntl(F_FULLFSYNC)`, which is a "true" `fsync` that
    actually forces data to hard disk platters (OS X's actual `fsync`
    is useless in the regard).

-k *CONSTRAINTS*, \--disable-constraints=*CONSTRAINTS*

  : Disable enforcement of the ordering constraints listed in the
    comma-separated list *CONSTRAINTS*.


-K *CONSTRAINTS*, \--enable-constraints=*CONSTRAINTS*

  : Enable enforcement of the ordering constraints listed in the
    comma-separated list *CONSTRAINTS*.

    Available ordering constraints are as follows:

> * *aio*: sequential ordering of asynchronous I/O operations (on by
>   default)

> * *fdstage*: stage ordering for regular-file file descriptors (on by
>   default)

> * *fdseq*: sequential ordering for regular-file file descriptors (on
>   by default)

> * *file*: sequential ordering for files (on by default)

> * *path*: stage ordering for paths (on by default)

> * *temporal*: temporal ordering of all events (off by default)

> * *specialfdseq*: sequential ordering for file descriptors referring
>    to special files (off by default)


-h, \--help

  : Print a usage summary to stdout and exit successfully.


-I, \--ignore-version-mismatch

  : When the required tool (`pahole`(1) from the \`dwarves' package)
    is available, the benchmark build process will embed version
    information into compiled benchmarks so that `artrun` can attempt
    to check for version mismatches between `artrun` itself and the
    version of `artc` used to compile the benchmark (such a mismatch
    is likely to produce segfaults and other misbehavior; don't do
    that).  This flag overrides the version check.  Its use is not
    advised, and should only be necessary in the event of a bug in the
    version-checking.  If you encounter a version mismatch,
    re-generate code for your benchmark and recompile it; *do not use
    this flag* if you're not 100% certain of a bug in the version
    checking.


-M, \--predelay-multi-cpu

  : Multiply predelays by the CPU count recorded in the iostat file
    passed to `artc`'s *-i*/*--iostat* flag.


-n, \--no-clear-cache

  : Do not attempt to clear the system page cache between benchmark
    initialization and execution (by default `artrun` will attempt to
    use its `clearcache` helper program to do this).


-p, \--prep-only

  : Exit after performing filesystem initialization; do not execute
    the benchmark.


-P, \--skip-prep

  : Skip filesystem initialization and immediately execute the
    benchmark (i.e. assume initialization has already been performed).
    In combination with *-p*/*--prep-only*, this allows inserting
    custom preparation steps (e.g. mounting a filesystem over a
    subtree) before executing a benchmark.  Note that if this isn't
    done properly things may go pear-shaped (deadlocks, nasal demons,
    etc.); use with care.


-q, \--skip-syscalls

  : Don't actually issue system calls when executing the benchmark,
    just go through the motions of spawning threads and exercising
    locking/signalling.  This is mostly intended for debugging
    `artrun` itself.


-R, \--use-urandom

  : Seed PRNG from /dev/urandom.


-r *SEED*, --prng-seed=*SEED*

  : Seed PRNG with *SEED*.


-S, \--simple-predelay

  : Consider only thread-ordering delays in computing predelay.  By
    default, predelay is computed based on the delays since the last
    event that satisfied each different constraint type.


-s, \--single-thread

  : Perform replay with a single thread (implies `-c 0', but this can
    be overridden with a subsequent *-c* flag if you really insist --
    don't expect meaningful results though).


-U, \--union-init

  : Don't delete or shrink existing files when performing filesystem
    initialization.  This allows preparing a filesystem subtree that
    is suitably set up to run multiple benchmarks concurrently
    (i.e. set each one up with \`artrun -p -U $FOO.so /some/dir' and
    then execute both concurrently with \`artrun -P $FOO.so
    /some/dir').


-w, \--randomize-init-data

  : Randomize data written to files during filesystem initialization.


-z, \--lazy-init

  : Instead of actually writing out data to files during filesystem
    initialization, instead just truncate them to the needed size.
    This can make initialization go a lot faster if a lot of data
    would otherwise be written and should be semantically
    indistinguishable; however, you should not expect to get
    meaningful performance numbers after using this.  If have ever
    used this flag, you should do an \`rm -rf' on *RUNDIR* before
    doing any runs for performance numbers.  *Do not use this flag
    unless you understand the above and know what you are doing.*

# OUTPUT

Upon completing benchmark execution (replay) `artrun` will dump lots
of information to stdout.  Each line of output should look like one of
the following:

* *prng_seed*: the PRNG seed used for the run.

* *command_line*: a copy of the command-line arguments passed to
  `artrun`

* *aio_latencies*: a list of entries of the form *SUB*:*CHECK*:*RET*,
  one for each AIO operation executed.  Each of *SUB*, *CHECK*, and
  *RET* is a time in nanoseconds since the call to submit the AIO
  request was made.  *SUB* is the time to complete the submission
  call; *CHECK* is the time at which `aio_return` or `io_getevents`
  was called, and *RET* is the time at which it returned.

* *thread_time(N)*: the total elapsed time (in nanoseconds) between
  thread *N*'s first replayed event and its termination.

* *thread_syscall_ns(N)*: the total time (in nanoseconds) that thread
  *N* spent in system calls.

* *thread_wait_ns(N)*: the total time (in nanoseconds) that thread *N*
  spent waiting for ordering constraints to be satisfied.

* *thread_sleep_ns(N)*: the total time (in nanoseconds) that thread
  *N* spent sleeping for predelay.

* *thread_utime(N)*: thread *N*'s total `ru_utime`, in seconds and
  microseconds, as reported by `getrusage`(2).  Only available if your
  system supports per-thread `getrusage`(2).

* *thread_stime(N)*: thread *N*'s total `ru_stime`, in seconds and
  microseconds, as reported by `getrusage`(2).  Only available if your
  system supports per-thread `getrusage`(2).

* *thread_inblock(N)*: thread *N*'s total `ru_inblock`, as reported by
  `getrusage`(2).  Only available if your system supports per-thread
  `getrusage`(2).

* *thread_oublock(N)*: thread *N*'s total `ru_oublock`, as reported by
  `getrusage`(2).  Only available if your system supports per-thread
  `getrusage`(2).

* *thread_log(N)*: a log of every system call made by thread *N*, with
  each entry being of the form *TYPE*:*START*:*LENGTH*.  *TYPE* is the
  kind of system call (e.g. `open`(2)), *START* is the time (in
  nanoseconds since the beginning of the trace) at which the call was
  issued, and *LENGTH* is the duration of time (also in nanoseconds)
  for which the call was outstanding (*START* + *LENGTH* is thus the
  time at which the call returned).

* *total_utime*: `ru_utime` across benchmark execution, in seconds and
  microseconds, as reported by `getrusage`(2).

* *total_stime*: `ru_stime` across benchmark execution, in seconds and
  microseconds, as reported by `getrusage`(2).

* *total_inblock*: `ru_inblock` across benchmark execution, as
  reported by `getrusage`(2).

* *total_oublock*: `ru_oublock` across benchmark execution, as
  reported by `getrusage`(2).

* *total_events*: the total number of events (system calls) replayed
  in the benchmark.

* *successful_events*: the number of replayed events whose return
  values matched expectations (i.e. replayed correctly).

* *failed_events*: the number of replayed events whose return values
  did not match expectations (i.e. replayed incorrectly).

* *success_rate*: the fraction of events that replayed correctly;
  *successful_events* / *total_events*.

* *elapsed_time*: the total elapsed time, in seconds, of the benchmark.

Additionally, when replaying on Linux, some extra I/O statistics are
available (see *Documentation/filesystems/proc.txt* in the kernel
source tree for details):

* *init_rchar*, *init_wchar*, *init_syscr*, *init_syscw*,
  *init_read_bytes*, *init_write_bytes*, *init_cancelled_write_bytes*:
  I/O statistics taken from /proc/self/io during the filesystem
  initialization performed prior to benchmark execution.

* *bench_rchar*, *bench_wchar*, *bench_syscr*, *bench_syscw*,
  *bench_read_bytes*, *bench_write_bytes*,
  *bench_cancelled_write_bytes*: I/O statistics taken from
  /proc/self/io during benchmark execution.


# SEE ALSO

`artc`(1), `strace-artc`(1), `geninit.sh`(1)
